{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import configparser\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('aws_credentials.cfg'))\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    ".builder \\\n",
    ".config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    ".config(\"spark.hadoop.fs.s3a.impl\",\"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    ".config(\"spark.hadoop.fs.s3a.awsAccessKeyId\", os.environ['AWS_ACCESS_KEY_ID']) \\\n",
    ".config(\"spark.hadoop.fs.s3a.awsSecretAccessKey\", os.environ['AWS_SECRET_ACCESS_KEY']) \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "country_codes_df = spark.read.parquet('s3a://udac-capstone-bucket/outputs/country_codes_table/*.parquet') \\\n",
    "                        .createOrReplaceTempView('country_codes')\n",
    "travel_mode_df = spark.read.parquet('s3a://udac-capstone-bucket/outputs/travel_mode_table/*.parquet') \\\n",
    "                        .createOrReplaceTempView('travel_mode')\n",
    "us_port_df = spark.read.parquet('s3a://udac-capstone-bucket/outputs/us_port_table/*.parquet') \\\n",
    "                        .createOrReplaceTempView('us_port')\n",
    "us_state_codes_df = spark.read.parquet('s3a://udac-capstone-bucket/outputs/us_state_codes_table/*.parquet') \\\n",
    "                        .createOrReplaceTempView('us_state_codes')\n",
    "visa_category_df = spark.read.parquet('s3a://udac-capstone-bucket/outputs/visa_category_table/*.parquet') \\\n",
    "                        .createOrReplaceTempView('visa_category')\n",
    "immigrants_df = spark.read.parquet('s3a://udac-capstone-bucket/outputs/immigrants_table/i94yr=2016/i94mon=4/*.parquet') \\\n",
    "                        .createOrReplaceTempView('immigrants')\n",
    "us_airport_codes_df = spark.read.parquet('s3a://udac-capstone-bucket/outputs/us_airport_codes_table/*/*.parquet') \\\n",
    "                        .createOrReplaceTempView('us_airport_codes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------+----------------+\n",
      "|country                                                  |immigrants_count|\n",
      "+---------------------------------------------------------+----------------+\n",
      "|UNITED KINGDOM                                           |360157          |\n",
      "|JAPAN                                                    |206873          |\n",
      "|CHINA, PRC                                               |191425          |\n",
      "|FRANCE                                                   |188766          |\n",
      "|MEXICO Air Sea, and Not Reported (I-94, no land arrivals)|175781          |\n",
      "|BRAZIL                                                   |129833          |\n",
      "|INDIA                                                    |110691          |\n",
      "|AUSTRALIA                                                |109884          |\n",
      "|ITALY                                                    |78535           |\n",
      "|NETHERLANDS                                              |76920           |\n",
      "+---------------------------------------------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the top 10 countries from where people were immigrated to US during Apr-2016\n",
    "spark.sql(\"\"\"\n",
    "    SELECT cc.country,\n",
    "           count(*) immigrants_count    \n",
    "    FROM   immigrants i,\n",
    "           country_codes cc\n",
    "    WHERE  i.i94cit = cc.country_Code\n",
    "    GROUP BY cc.country\n",
    "    ORDER BY immigrants_count DESC\n",
    "    LIMIT 10\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+\n",
      "|category|tourists_count|\n",
      "+--------+--------------+\n",
      "|Pleasure|2530868       |\n",
      "+--------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the count of people came to US for tourism during Apr-2016\n",
    "spark.sql(\"\"\"\n",
    "    SELECT vc.category,\n",
    "           count(*) tourists_count    \n",
    "    FROM   immigrants i,\n",
    "           visa_category vc\n",
    "    WHERE  i.i94visa = vc.category_Code\n",
    "    AND    vc.category = 'Pleasure'\n",
    "    GROUP BY vc.category\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
